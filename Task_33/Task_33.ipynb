{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    W1 = np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = Z2  \n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, Z1, A1, Z2, A2, W1, W2, b1, b2, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # This one is output layer error calculations  \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(A1.T, dZ2)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    # This one is hidden layer error calculations \n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = (1/m) * np.dot(X.T, dZ1)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    # Here updating the weights\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X, Y, hidden_size, learning_rate, epochs):\n",
    "    input_size = X.shape[1]\n",
    "    output_size = Y.shape[1]\n",
    "    \n",
    "    # For Training First Initialize weights and biases\n",
    "    W1, b1, W2, b2 = initialize_weights(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Now There Performing The Training loop\n",
    "    for epoch in range(epochs):\n",
    "        Z1, A1, Z2, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
    "        W1, b1, W2, b2 = backward_propagation(X, Y, Z1, A1, Z2, A2, W1, W2, b1, b2, learning_rate)\n",
    "        \n",
    "        if (epoch+1) % 100 == 0:\n",
    "            loss = mse(Y, A2)\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss}')\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 0.007342673399887166\n",
      "Epoch 200/1000, Loss: 0.007161119375479756\n",
      "Epoch 300/1000, Loss: 0.007058813891053291\n",
      "Epoch 400/1000, Loss: 0.006991146622534722\n",
      "Epoch 500/1000, Loss: 0.006946290366381214\n",
      "Epoch 600/1000, Loss: 0.006916506476326313\n",
      "Epoch 700/1000, Loss: 0.006896704166036524\n",
      "Epoch 800/1000, Loss: 0.006883524142501039\n",
      "Epoch 900/1000, Loss: 0.006874744152007524\n",
      "Epoch 1000/1000, Loss: 0.0068688911544037175\n",
      "Predictions: [[0.67307369]\n",
      " [0.26281658]\n",
      " [1.08333079]\n",
      " [0.87820224]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Here I Am Defining input data and target labels\n",
    "    X = np.array([[0.5], [0.1], [0.9], [0.7]])\n",
    "    Y = np.array([[0.8], [0.2], [1.0], [0.9]])\n",
    "\n",
    "    # This One Hyperparameters\n",
    "    hidden_size = 5\n",
    "    learning_rate = 0.01\n",
    "    epochs = 1000\n",
    "\n",
    "    # Training the neural network\n",
    "    W1, b1, W2, b2 = train_neural_network(X, Y, hidden_size, learning_rate, epochs)\n",
    "\n",
    "    # There I made the Predictions\n",
    "    _, _, _, predictions = forward_propagation(X, W1, b1, W2, b2)\n",
    "    print(\"Predictions:\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
